{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SetUp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "from langchain_aws import ChatBedrockConverse\n",
    "from langchain_aws import AmazonKnowledgeBasesRetriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up Bedrock LLM\n",
    "bedrock_client = boto3.client(\"bedrock-runtime\", region_name=\"us-west-1\")\n",
    "model_id = \"us.amazon.nova-lite-v1:0\"\n",
    "provider_id = \"amazon\"\n",
    "\n",
    "llm = ChatBedrockConverse(\n",
    "    model=model_id,\n",
    "    provider=provider_id,\n",
    "    temperature=0.5,\n",
    "    max_tokens=None,\n",
    "    client=bedrock_client\n",
    ")\n",
    "\n",
    "# TODO: Set your Bedrock Knowledge Base ID here\n",
    "knowledge_base_id = \"\"  # <-- FILL THIS IN\n",
    "\n",
    "retriever = AmazonKnowledgeBasesRetriever(\n",
    "    knowledge_base_id=knowledge_base_id,\n",
    "    region_name=\"us-west-1\",\n",
    "    retrieval_config={\"vectorSearchConfiguration\": {\"numberOfResults\": 4}},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.tools import tool\n",
    "\n",
    "@tool(response_format=\"content_and_artifact\")\n",
    "def retrieve(query: str):\n",
    "    \"\"\"Retrieve information related to a query.\"\"\"\n",
    "    docs = retriever.invoke(query)\n",
    "    serialized = \"\\n\\n\".join(\n",
    "        (f\"Source: {getattr(doc, 'metadata', {})}\\nContent: {getattr(doc, 'page_content', str(doc))}\")\n",
    "        for doc in docs\n",
    "    )\n",
    "    return serialized, docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import SystemMessage\n",
    "from langgraph.prebuilt import ToolNode\n",
    "from langgraph.graph import MessagesState\n",
    "\n",
    "\n",
    "# Step 1: Generate an AIMessage that may include a tool-call to be sent.\n",
    "def query_or_respond(state: MessagesState):\n",
    "    \"\"\"Generate tool call for retrieval or respond.\"\"\"\n",
    "    llm_with_tools = llm.bind_tools([retrieve])\n",
    "    response = llm_with_tools.invoke(state[\"messages\"])\n",
    "    # MessagesState appends messages to state instead of overwriting\n",
    "    return {\"messages\": [response]}\n",
    "\n",
    "\n",
    "# Step 2: Execute the retrieval.\n",
    "tools = ToolNode([retrieve])\n",
    "\n",
    "\n",
    "# Step 3: Generate a response using the retrieved content.\n",
    "def generate(state: MessagesState):\n",
    "    \"\"\"Generate answer.\"\"\"\n",
    "    # Get generated ToolMessages\n",
    "    recent_tool_messages = []\n",
    "    for message in reversed(state[\"messages\"]):\n",
    "        if message.type == \"tool\":\n",
    "            recent_tool_messages.append(message)\n",
    "        else:\n",
    "            break\n",
    "    tool_messages = recent_tool_messages[::-1]\n",
    "\n",
    "    # Format into prompt\n",
    "    docs_content = \"\\n\\n\".join(doc.content for doc in tool_messages)\n",
    "    system_message_content = (\n",
    "        \"You are an assistant for question-answering tasks. \"\n",
    "        \"Use the following pieces of retrieved context to answer \"\n",
    "        \"the question. If you don't know the answer, say that you \"\n",
    "        \"don't know. Use three sentences maximum and keep the \"\n",
    "        \"answer concise.\"\n",
    "        \"\\n\\n\"\n",
    "        f\"{docs_content}\"\n",
    "    )\n",
    "    conversation_messages = [\n",
    "        message\n",
    "        for message in state[\"messages\"]\n",
    "        if message.type in (\"human\", \"system\")\n",
    "        or (message.type == \"ai\" and not message.tool_calls)\n",
    "    ]\n",
    "    prompt = [SystemMessage(system_message_content)] + conversation_messages\n",
    "\n",
    "    # Run\n",
    "    response = llm.invoke(prompt)\n",
    "    return {\"messages\": [response]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import END\n",
    "from langgraph.prebuilt import tools_condition\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "from langgraph.graph import StateGraph\n",
    "\n",
    "memory = MemorySaver()\n",
    "\n",
    "graph_builder = StateGraph(MessagesState)\n",
    "graph_builder.add_node(query_or_respond)\n",
    "graph_builder.add_node(tools)\n",
    "graph_builder.add_node(generate)\n",
    "\n",
    "graph_builder.set_entry_point(\"query_or_respond\")\n",
    "graph_builder.add_conditional_edges(\n",
    "    \"query_or_respond\",\n",
    "    tools_condition,\n",
    "    {END: END, \"tools\": \"tools\"},\n",
    ")\n",
    "graph_builder.add_edge(\"tools\", \"generate\")\n",
    "graph_builder.add_edge(\"generate\", END)\n",
    "\n",
    "graph = graph_builder.compile(checkpointer=memory)\n",
    "# Specify an ID for the thread\n",
    "config = {\"configurable\": {\"thread_id\": \"abc123\"}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import Image, display\n",
    "\n",
    "display(Image(graph.get_graph().draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "when should you build an agent?\n"
     ]
    },
    {
     "ename": "ValidationException",
     "evalue": "An error occurred (ValidationException) when calling the Converse operation: The provided model identifier is invalid.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValidationException\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[50]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m input_message = \u001b[33m\"\u001b[39m\u001b[33mwhen should you build an agent?\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m \u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstep\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mgraph\u001b[49m\u001b[43m.\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      4\u001b[39m \u001b[43m    \u001b[49m\u001b[43m{\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmessages\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43m{\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mrole\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43muser\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcontent\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_message\u001b[49m\u001b[43m}\u001b[49m\u001b[43m]\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      5\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstream_mode\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mvalues\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m      6\u001b[39m \u001b[43m    \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      7\u001b[39m \u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m      8\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstep\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmessages\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[43m-\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpretty_print\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/RAG-powered_medical_assistant/.venv/lib/python3.12/site-packages/langgraph/pregel/__init__.py:2436\u001b[39m, in \u001b[36mPregel.stream\u001b[39m\u001b[34m(self, input, config, stream_mode, output_keys, interrupt_before, interrupt_after, checkpoint_during, debug, subgraphs)\u001b[39m\n\u001b[32m   2434\u001b[39m         \u001b[38;5;28;01mfor\u001b[39;00m task \u001b[38;5;129;01min\u001b[39;00m loop.match_cached_writes():\n\u001b[32m   2435\u001b[39m             loop.output_writes(task.id, task.writes, cached=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m-> \u001b[39m\u001b[32m2436\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m_\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrunner\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtick\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2437\u001b[39m \u001b[43m            \u001b[49m\u001b[43m[\u001b[49m\u001b[43mt\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mloop\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtasks\u001b[49m\u001b[43m.\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m.\u001b[49m\u001b[43mwrites\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2438\u001b[39m \u001b[43m            \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mstep_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2439\u001b[39m \u001b[43m            \u001b[49m\u001b[43mget_waiter\u001b[49m\u001b[43m=\u001b[49m\u001b[43mget_waiter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2440\u001b[39m \u001b[43m            \u001b[49m\u001b[43mschedule_task\u001b[49m\u001b[43m=\u001b[49m\u001b[43mloop\u001b[49m\u001b[43m.\u001b[49m\u001b[43maccept_push\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2441\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m   2442\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;66;43;03m# emit output\u001b[39;49;00m\n\u001b[32m   2443\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01myield from\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43moutput\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2444\u001b[39m \u001b[38;5;66;03m# emit output\u001b[39;00m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[47]\u001b[39m\u001b[32m, line 10\u001b[39m, in \u001b[36mquery_or_respond\u001b[39m\u001b[34m(state)\u001b[39m\n\u001b[32m      8\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Generate tool call for retrieval or respond.\"\"\"\u001b[39;00m\n\u001b[32m      9\u001b[39m llm_with_tools = llm.bind_tools([retrieve])\n\u001b[32m---> \u001b[39m\u001b[32m10\u001b[39m response = \u001b[43mllm_with_tools\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstate\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmessages\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     11\u001b[39m \u001b[38;5;66;03m# MessagesState appends messages to state instead of overwriting\u001b[39;00m\n\u001b[32m     12\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m {\u001b[33m\"\u001b[39m\u001b[33mmessages\u001b[39m\u001b[33m\"\u001b[39m: [response]}\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/RAG-powered_medical_assistant/.venv/lib/python3.12/site-packages/langchain_core/runnables/base.py:5430\u001b[39m, in \u001b[36mRunnableBindingBase.invoke\u001b[39m\u001b[34m(self, input, config, **kwargs)\u001b[39m\n\u001b[32m   5423\u001b[39m \u001b[38;5;129m@override\u001b[39m\n\u001b[32m   5424\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34minvoke\u001b[39m(\n\u001b[32m   5425\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m   5428\u001b[39m     **kwargs: Optional[Any],\n\u001b[32m   5429\u001b[39m ) -> Output:\n\u001b[32m-> \u001b[39m\u001b[32m5430\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbound\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   5431\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   5432\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_merge_configs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5433\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43m{\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5434\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/RAG-powered_medical_assistant/.venv/lib/python3.12/site-packages/langchain_core/language_models/chat_models.py:371\u001b[39m, in \u001b[36mBaseChatModel.invoke\u001b[39m\u001b[34m(self, input, config, stop, **kwargs)\u001b[39m\n\u001b[32m    359\u001b[39m \u001b[38;5;129m@override\u001b[39m\n\u001b[32m    360\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34minvoke\u001b[39m(\n\u001b[32m    361\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    366\u001b[39m     **kwargs: Any,\n\u001b[32m    367\u001b[39m ) -> BaseMessage:\n\u001b[32m    368\u001b[39m     config = ensure_config(config)\n\u001b[32m    369\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(\n\u001b[32m    370\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mChatGeneration\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m--> \u001b[39m\u001b[32m371\u001b[39m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgenerate_prompt\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    372\u001b[39m \u001b[43m            \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_convert_input\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    373\u001b[39m \u001b[43m            \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    374\u001b[39m \u001b[43m            \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcallbacks\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    375\u001b[39m \u001b[43m            \u001b[49m\u001b[43mtags\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtags\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    376\u001b[39m \u001b[43m            \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmetadata\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    377\u001b[39m \u001b[43m            \u001b[49m\u001b[43mrun_name\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mrun_name\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    378\u001b[39m \u001b[43m            \u001b[49m\u001b[43mrun_id\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpop\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mrun_id\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    379\u001b[39m \u001b[43m            \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    380\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m.generations[\u001b[32m0\u001b[39m][\u001b[32m0\u001b[39m],\n\u001b[32m    381\u001b[39m     ).message\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/RAG-powered_medical_assistant/.venv/lib/python3.12/site-packages/langchain_core/language_models/chat_models.py:956\u001b[39m, in \u001b[36mBaseChatModel.generate_prompt\u001b[39m\u001b[34m(self, prompts, stop, callbacks, **kwargs)\u001b[39m\n\u001b[32m    947\u001b[39m \u001b[38;5;129m@override\u001b[39m\n\u001b[32m    948\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mgenerate_prompt\u001b[39m(\n\u001b[32m    949\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    953\u001b[39m     **kwargs: Any,\n\u001b[32m    954\u001b[39m ) -> LLMResult:\n\u001b[32m    955\u001b[39m     prompt_messages = [p.to_messages() \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m prompts]\n\u001b[32m--> \u001b[39m\u001b[32m956\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompt_messages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/RAG-powered_medical_assistant/.venv/lib/python3.12/site-packages/langchain_core/language_models/chat_models.py:775\u001b[39m, in \u001b[36mBaseChatModel.generate\u001b[39m\u001b[34m(self, messages, stop, callbacks, tags, metadata, run_name, run_id, **kwargs)\u001b[39m\n\u001b[32m    772\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i, m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(input_messages):\n\u001b[32m    773\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    774\u001b[39m         results.append(\n\u001b[32m--> \u001b[39m\u001b[32m775\u001b[39m             \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_generate_with_cache\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    776\u001b[39m \u001b[43m                \u001b[49m\u001b[43mm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    777\u001b[39m \u001b[43m                \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    778\u001b[39m \u001b[43m                \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrun_managers\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrun_managers\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    779\u001b[39m \u001b[43m                \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    780\u001b[39m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    781\u001b[39m         )\n\u001b[32m    782\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    783\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m run_managers:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/RAG-powered_medical_assistant/.venv/lib/python3.12/site-packages/langchain_core/language_models/chat_models.py:1021\u001b[39m, in \u001b[36mBaseChatModel._generate_with_cache\u001b[39m\u001b[34m(self, messages, stop, run_manager, **kwargs)\u001b[39m\n\u001b[32m   1019\u001b[39m     result = generate_from_stream(\u001b[38;5;28miter\u001b[39m(chunks))\n\u001b[32m   1020\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m inspect.signature(\u001b[38;5;28mself\u001b[39m._generate).parameters.get(\u001b[33m\"\u001b[39m\u001b[33mrun_manager\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m-> \u001b[39m\u001b[32m1021\u001b[39m     result = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_generate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1022\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\n\u001b[32m   1023\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1024\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1025\u001b[39m     result = \u001b[38;5;28mself\u001b[39m._generate(messages, stop=stop, **kwargs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/RAG-powered_medical_assistant/.venv/lib/python3.12/site-packages/langchain_aws/chat_models/bedrock_converse.py:653\u001b[39m, in \u001b[36mChatBedrockConverse._generate\u001b[39m\u001b[34m(self, messages, stop, run_manager, **kwargs)\u001b[39m\n\u001b[32m    651\u001b[39m logger.debug(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mInput params: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mparams\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m    652\u001b[39m logger.info(\u001b[33m\"\u001b[39m\u001b[33mUsing Bedrock Converse API to generate response\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m653\u001b[39m response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mclient\u001b[49m\u001b[43m.\u001b[49m\u001b[43mconverse\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    654\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbedrock_messages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msystem\u001b[49m\u001b[43m=\u001b[49m\u001b[43msystem\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mparams\u001b[49m\n\u001b[32m    655\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    656\u001b[39m logger.debug(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mResponse from Bedrock: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresponse\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m    657\u001b[39m response_message = _parse_response(response)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/RAG-powered_medical_assistant/.venv/lib/python3.12/site-packages/botocore/client.py:595\u001b[39m, in \u001b[36mClientCreator._create_api_method.<locals>._api_call\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m    591\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[32m    592\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpy_operation_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m() only accepts keyword arguments.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    593\u001b[39m     )\n\u001b[32m    594\u001b[39m \u001b[38;5;66;03m# The \"self\" in this scope is referring to the BaseClient.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m595\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_make_api_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43moperation_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/RAG-powered_medical_assistant/.venv/lib/python3.12/site-packages/botocore/context.py:123\u001b[39m, in \u001b[36mwith_current_context.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    121\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m hook:\n\u001b[32m    122\u001b[39m     hook()\n\u001b[32m--> \u001b[39m\u001b[32m123\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/RAG-powered_medical_assistant/.venv/lib/python3.12/site-packages/botocore/client.py:1058\u001b[39m, in \u001b[36mBaseClient._make_api_call\u001b[39m\u001b[34m(self, operation_name, api_params)\u001b[39m\n\u001b[32m   1054\u001b[39m     error_code = error_info.get(\u001b[33m\"\u001b[39m\u001b[33mQueryErrorCode\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m error_info.get(\n\u001b[32m   1055\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mCode\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1056\u001b[39m     )\n\u001b[32m   1057\u001b[39m     error_class = \u001b[38;5;28mself\u001b[39m.exceptions.from_code(error_code)\n\u001b[32m-> \u001b[39m\u001b[32m1058\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m error_class(parsed_response, operation_name)\n\u001b[32m   1059\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1060\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m parsed_response\n",
      "\u001b[31mValidationException\u001b[39m: An error occurred (ValidationException) when calling the Converse operation: The provided model identifier is invalid.",
      "During task with name 'query_or_respond' and id 'b821bf8c-2461-9ebf-1b50-b57a8c69a82d'"
     ]
    }
   ],
   "source": [
    "input_message = \"when should you build an agent?\"\n",
    "\n",
    "for step in graph.stream(\n",
    "    {\"messages\": [{\"role\": \"user\", \"content\": input_message}]},\n",
    "    stream_mode=\"values\",\n",
    "    config=config,\n",
    "):\n",
    "    step[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_message = \"Can you look up some common ways of doing it?\"\n",
    "\n",
    "for step in graph.stream(\n",
    "    {\"messages\": [{\"role\": \"user\", \"content\": input_message}]},\n",
    "    stream_mode=\"values\",\n",
    "    config=config,\n",
    "):\n",
    "    step[\"messages\"][-1].pretty_print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
